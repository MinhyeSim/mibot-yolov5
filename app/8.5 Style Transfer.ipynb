{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8.5 Style Transfer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"aY_zZQI-w9h1"},"source":["# 8. 비지도 학습\n","## 8.5 이미지 스타일 변이"]},{"cell_type":"code","metadata":{"id":"3raHB8TjNqyW"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","#import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"joM2y6bIfJ52"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"refCL9C2fKqz"},"source":["cd/content/gdrive/My Drive/pytorch_dlbro"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GAYheyghlrcH"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8rfy56ZHFrHn"},"source":["## 손실함수"]},{"cell_type":"code","metadata":{"id":"M2R7bHj3N-JR"},"source":["class ContentLoss(nn.Module):\n","    def __init__(self, target,):\n","        super(ContentLoss, self).__init__()\n","        self.target = target.detach()\n","\n","    def forward(self, input):\n","        self.loss = F.mse_loss(input, self.target)\n","        return input"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSWMpxZcmMOc"},"source":["def gram_matrix(input):\n","    a, b, c, d = input.size()\n","    features = input.view(a * b, c * d)  \n","    G = torch.mm(features, features.t())\n","    # we 'normalize' the values of the gram matrix\n","    # by dividing by the number of element in each feature maps.\n","    return G.div(a * b * c * d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ntJQRBt3mPB6"},"source":["class StyleLoss(nn.Module):\n","    def __init__(self, target_feature):\n","        super(StyleLoss, self).__init__()\n","        self.target = gram_matrix(target_feature).detach()\n","\n","    def forward(self, input):\n","        G = gram_matrix(input)\n","        self.loss = F.mse_loss(G, self.target)\n","        return input"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xc0OW1gryBna"},"source":["## 모델 정의"]},{"cell_type":"code","metadata":{"id":"QOKs7hJ6GxbL"},"source":["cnn = models.vgg19(pretrained=True).features.to(device).eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y8fm-JTqOAM0"},"source":["class Normalization(nn.Module):\n","    def __init__(self, mean, std):\n","        super(Normalization, self).__init__()\n","        self.mean = mean.view(-1, 1, 1)\n","        self.std = std.view(-1, 1, 1)\n","\n","    def forward(self, img):\n","        return (img - self.mean) / self.std"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mKh9MxEhyN9h"},"source":["## 모델 재정의"]},{"cell_type":"code","metadata":{"id":"0d3W7XoROCgF"},"source":["def get_style_model_and_losses(cnn, style_img, content_img):\n","\n","    #cnn = copy.deepcopy(cnn)\n","    content_layers = ['conv_4'] # 피쳐맵을 추출하려는 컨텐츠 레이어\n","    style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5'] # 관심있는 스타일 레이어들\n","    normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device) # 정규화를 위한 평균 정의\n","    normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device) # 정규화를 위한 표준편차 정의\n","    normalization = Normalization(normalization_mean, normalization_std).to(device)\n","\n","    content_losses = [] # 컨텐츠 손실 함수 저장 리스트\n","    style_losses = [] # 스타일 손실 함수 저장 리스트\n","\n","    model = nn.Sequential(normalization) # 입력값을 정규화한다.\n","\n","    i = 0  \n","    for layer in cnn.children(): # 층 정보를 하나 씩 불러와 모델 구축\n","        if isinstance(layer, nn.Conv2d):\n","            i += 1\n","            name = 'conv_{}'.format(i)\n","        elif isinstance(layer, nn.ReLU):\n","            name = 'relu_{}'.format(i)\n","            layer = nn.ReLU(inplace=False)\n","        elif isinstance(layer, nn.MaxPool2d):\n","            name = 'maxpool_{}'.format(i)\n","        elif isinstance(layer, nn.BatchNorm2d):\n","            name = 'bn_{}'.format(i)\n","        else:\n","            raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n","\n","        model.add_module(name, layer)\n","\n","        if name in content_layers: # 원하는 컨텐츠 레이어에서 손실함수를 계산을 추가한다.\n","            target = model(content_img)\n","            content_loss = ContentLoss(target)\n","            model.add_module(\"content_loss_{}\".format(i), content_loss)\n","            content_losses.append(content_loss)\n","\n","        if name in style_layers: # 원하는 스타일 레이어에서 손실함수를 계산을 추가한다.\n","            target_feature = model(style_img)\n","            style_loss = StyleLoss(target_feature)\n","            model.add_module(\"style_loss_{}\".format(i), style_loss)\n","            style_losses.append(style_loss)\n","\n","    for i in range(len(model) - 1, -1, -1): # 모델을 뒤 부터 확인하여 가장 마지막 위치의 손실 함수를 확인한다.\n","        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n","            break\n","\n","    model = model[:(i + 1)] # 사용할 층까지만 잘라서 모델을 재정의\n","\n","    return model, style_losses, content_losses"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4mzczr8BPSP"},"source":["## 최적화 기법 및 학습 정의"]},{"cell_type":"code","metadata":{"id":"9rpbNVz3A6lp"},"source":["def run_style_transfer(cnn, content_img, style_img, num_steps=300, style_weight=100000, content_weight=1):\n","\n","    input_img = content_img.clone().detach().requires_grad_(True)\n","    model, style_losses, content_losses = get_style_model_and_losses(cnn, style_img, content_img)\n","    optimizer = optim.LBFGS([input_img])\n","    iteration = [0]\n","    while iteration[0] <= num_steps:\n","        def closure():  \n","            input_img.data.clamp_(0, 1) # 0이상 1이하의 값만 사용한다.\n","            optimizer.zero_grad()\n","            model(input_img) # 손실 함수들이 들어가 재정의 된 모델이다.\n","            style_score = 0\n","            content_score = 0\n","\n","            for sl in style_losses:\n","                style_score += sl.loss # 각 레이어들의 손실 MSE 함수를 불러와 더한다.\n","            for cl in content_losses:\n","                content_score += cl.loss # 각 레이어들의 손실 MSE 함수를 불러와 더한다.\n","\n","            loss = style_weight*style_score + content_weight*content_score # 가중치를 결합한 최종 손실 함수 정의\n","            loss.backward()\n","\n","            iteration[0] += 1\n","            if iteration[0] % 50 == 0:\n","                print('Iteration {}: Style Loss : {:4f} Content Loss: {:4f}'.format(\n","                    iteration[0], style_score.item(), content_score.item()))\n","\n","            return style_score + content_score\n","\n","        optimizer.step(closure)\n","\n","    return input_img.data.clamp_(0, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5UmrRE76BVCV"},"source":["## 이미지 불러오기 및 모델 실행하기"]},{"cell_type":"code","metadata":{"id":"noKhwCkUmk_U"},"source":["def image_loader(img_path):\n","    loader = transforms.Compose([transforms.Resize((256)), transforms.ToTensor()]) \n","    image = Image.open(img_path).convert('RGB')   \n","    image = loader(image).unsqueeze(0) # 4차원 텐서 변환\n","    return image.to(device)\n","\n","style_img = image_loader(\"./data/imgA.jpg\")\n","content_img = image_loader(\"./data/imgB.jpg\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LgeC0umQURr6"},"source":["output = run_style_transfer(cnn, content_img, style_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6kNucZtJviO"},"source":["def imshow(image, title):\n","    unloader = transforms.ToPILImage()\n","    image = unloader(image.squeeze(0).cpu())\n","    plt.figure(figsize=(5,5))\n","    plt.imshow(image)\n","    plt.title(title)\n","    plt.axis(\"off\")\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUwFT5tyoj2N"},"source":["imshow(output, title='Output Image')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dTIJzGmImnHA"},"source":["imshow(content_img, title='Input Image')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M--xho0BpECo"},"source":["imshow(style_img, title='Style Image')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjf8l_sBnNrn"},"source":[""],"execution_count":null,"outputs":[]}]}